{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UpiKp0C8Gi-K"
   },
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhgrCqw8Gjjy",
    "outputId": "1a72ee81-e635-4117-df14-d6052fb847bf"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCtwm-S9KYBH"
   },
   "source": [
    "### Male-Female Recognition with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dydXIaoseUwv",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os  # Import the os module for file and path operations\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from keras.applications import Xception\n",
    "from skimage.filters import gabor\n",
    "from skimage import color\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "model_vgg16 = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AScSNNw-IGvL",
    "outputId": "0bb90bd0-60d4-4840-fe7a-9a5c24faf8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 5950\n",
      "Total number of unique labels/classes: 2\n",
      "Labels/classes: {'M', 'F'}\n",
      "\n",
      "Original Image Shape: (5950, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Assuming your dataset is stored in a folder called 'path'\n",
    "dataset_path = 'Real'\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "def load_dataset(dataset_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        img_path = os.path.join(dataset_path, filename)\n",
    "        if os.path.isfile(img_path):  # Check if it's a file\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # Read in color\n",
    "\n",
    "            # Resize the image to (224, 224)\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "\n",
    "            images.append(img)\n",
    "\n",
    "            # Extract gender information (assumed to be the first character after the ID)\n",
    "            gender = filename.split('__')[1][0]\n",
    "            labels.append(gender)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load your dataset\n",
    "images, labels = load_dataset(dataset_path)\n",
    "# Check information about the loaded dataset\n",
    "print(f\"Total number of images: {len(images)}\")\n",
    "print(f\"Total number of unique labels/classes: {len(set(labels))}\")\n",
    "print(f\"Labels/classes: {set(labels)}\\n\")\n",
    "\n",
    "# Preprocess the images for VGG16\n",
    "images = preprocess_input(images)\n",
    "\n",
    "# Print the shape of the images\n",
    "print(\"Original Image Shape:\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyGcnYrxHVnA",
    "outputId": "f359140e-6873-4b3d-921b-e6299a492452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Number of training samples: 4760\n",
      "Number of testing samples: 595\n",
      "Number of validation samples: 595\n",
      "\n",
      "Number of unique labels/classes in training set: 2\n",
      "Number of unique labels/classes in testing set: 2\n",
      "Number of unique labels/classes in validation set: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert labels to numeric format\n",
    "labels = np.array([0 if label == 'F' else 1 for label in labels])\n",
    "\n",
    "# Print the first 10 labels for verification\n",
    "print(labels[:10])\n",
    "\n",
    "# Step 3: Split the dataset into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check information about the split dataset\n",
    "print(f\"Number of training samples: {len(X_train)}\")\n",
    "print(f\"Number of testing samples: {len(X_test)}\")\n",
    "print(f\"Number of validation samples: {len(X_val)}\")\n",
    "\n",
    "print(f\"\\nNumber of unique labels/classes in training set: {len(set(y_train))}\")\n",
    "print(f\"Number of unique labels/classes in testing set: {len(set(y_test))}\")\n",
    "print(f\"Number of unique labels/classes in validation set: {len(set(y_val))}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cw69PDUtZ9B"
   },
   "source": [
    "#### AlexNet-like model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9WvBPAPrGj8"
   },
   "outputs": [],
   "source": [
    "# # Evaluate the model on the train set\n",
    "# test_loss, test_accuracy = model.evaluate(X_train, y_train)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgkM4mKNrKuD"
   },
   "outputs": [],
   "source": [
    "# # Evaluate the model on the test set\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f'Test Loss: {test_loss:.4f}')\n",
    "# print(f'Test Accuracy: {test_accuracy:.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qx9x35Svtd0c"
   },
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CqE82RMi5yl3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 30s 1us/step\n",
      "149/149 [==============================] - 599s 4s/step\n",
      "19/19 [==============================] - 71s 4s/step\n",
      "19/19 [==============================] - 69s 4s/step\n",
      "VGG16 Features (Training): (4760, 25088)\n",
      "VGG16 Features (Testing): (595, 25088)\n",
      "VGG16 Features (validation): (595, 25088)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load pre-trained VGG16 model\n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling=None, classes=2)\n",
    "\n",
    "\n",
    "# Step 7: Extract features from the deeper layers of the AlexNet model\n",
    "\n",
    "# Extract features from VGG16\n",
    "fc_features_train = model_vgg16.predict(X_train)\n",
    "fc_features_test = model_vgg16.predict(X_test)\n",
    "fc_features_val = model_vgg16.predict(X_test)\n",
    "\n",
    "# Flatten the features\n",
    "fc_features_train_flat = fc_features_train.reshape(fc_features_train.shape[0], -1)\n",
    "fc_features_test_flat = fc_features_test.reshape(fc_features_test.shape[0], -1)\n",
    "fc_features_val_flat = fc_features_val.reshape(fc_features_val.shape[0], -1)\n",
    "\n",
    "\n",
    "# Output: Extracted features\n",
    "print(\"VGG16 Features (Training):\", fc_features_train_flat.shape)\n",
    "print(\"VGG16 Features (Testing):\", fc_features_test_flat.shape)\n",
    "print(\"VGG16 Features (validation):\", fc_features_val_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.filters import gabor\n",
    "\n",
    "# def apply_gabor_filters(image):\n",
    "#     scales = [1, 2, 4, 8]\n",
    "#     angles = [0, 45, 90, 135, 180, 225, 270, 315]\n",
    "#     gabor_features = []\n",
    "\n",
    "#     for scale in scales:\n",
    "#         for angle in angles:\n",
    "#             gabor_filter_real, gabor_filter_imag = gabor(image[:, :, 0], frequency=1/scale, theta=angle)\n",
    "#             gabor_magnitude = np.sqrt(gabor_filter_real**2 + gabor_filter_imag**2)\n",
    "#             gabor_features.extend([np.mean(gabor_magnitude), np.std(gabor_magnitude)])\n",
    "\n",
    "#     return np.array(gabor_features)\n",
    "\n",
    "# # Apply Gabor filters to the training set\n",
    "# gabor_features_train = np.array([apply_gabor_filters(img) for img in X_train])\n",
    "# print(\"Xtrain Done\")\n",
    "\n",
    "# # Apply Gabor filters to the testing set\n",
    "# gabor_features_test = np.array([apply_gabor_filters(img) for img in X_test])\n",
    "# print(\"Xtest Done\")\n",
    "\n",
    "# # Apply Gabor filters to the validation set\n",
    "# gabor_features_val = np.array([apply_gabor_filters(img) for img in X_val])\n",
    "# print(\"Xval Done\")\n",
    "\n",
    "# # Step 9: Fusion of features in Vector (V)\n",
    "# fusion_feature_vector_train = np.concatenate((fc_features_train_flat, gabor_features_train), axis=1)\n",
    "# fusion_feature_vector_test = np.concatenate((fc_features_test_flat, gabor_features_test), axis=1)\n",
    "# fusion_feature_vector_val = np.concatenate((fc_features_val_flat, gabor_features_val), axis=1)\n",
    "\n",
    "# # Output: Extract fusion feature vector (V)\n",
    "# print(\"Fusion Feature Vector (Training):\", fusion_feature_vector_train.shape)\n",
    "# print(\"Fusion Feature Vector (Testing):\", fusion_feature_vector_test.shape)\n",
    "# print(\"Fusion Feature Vector (Validation):\", fusion_feature_vector_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion Feature Vector (Training): (4760, 25088)\n",
      "Fusion Feature Vector (Testing): (595, 25088)\n",
      "Fusion Feature Vector (Validation): (595, 25088)\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Fusion of features in Vector (V)\n",
    "fusion_feature_vector_train = fc_features_train_flat\n",
    "fusion_feature_vector_test = fc_features_test_flat\n",
    "fusion_feature_vector_val = fc_features_val_flat\n",
    "\n",
    "# Output: Extract fusion feature vector (V)\n",
    "print(\"Fusion Feature Vector (Training):\", fusion_feature_vector_train.shape)\n",
    "print(\"Fusion Feature Vector (Testing):\", fusion_feature_vector_test.shape)\n",
    "print(\"Fusion Feature Vector (Validation):\", fusion_feature_vector_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVS2Opd6uCg2"
   },
   "source": [
    "Now fusion_feature_vector_train,  fusion_feature_vector_val, and fusion_feature_vector_test can be used to train and evaluate your machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfLKPFiI6_Hb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G07JJuXtVX1"
   },
   "source": [
    "Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "W4oQa6sRdjPh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "149/149 [==============================] - 3s 16ms/step - loss: 1.1199 - accuracy: 0.7798 - val_loss: 0.6005 - val_accuracy: 0.7748\n",
      "Epoch 2/50\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.4634 - accuracy: 0.7985 - val_loss: 0.6615 - val_accuracy: 0.7731\n",
      "Epoch 3/50\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.4210 - accuracy: 0.7998 - val_loss: 0.6221 - val_accuracy: 0.7748\n",
      "Epoch 4/50\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.4091 - accuracy: 0.7992 - val_loss: 0.6307 - val_accuracy: 0.7748\n",
      "Epoch 5/50\n",
      "149/149 [==============================] - 2s 15ms/step - loss: 0.3856 - accuracy: 0.8000 - val_loss: 0.7656 - val_accuracy: 0.7748\n",
      "Epoch 6/50\n",
      "149/149 [==============================] - 2s 16ms/step - loss: 0.3481 - accuracy: 0.8006 - val_loss: 0.8119 - val_accuracy: 0.7748\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Build a CNN model for classification\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "classification_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(fusion_feature_vector_train.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification, so use 'sigmoid' activation\n",
    "])\n",
    "\n",
    "# Compile the classification model\n",
    "classification_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = classification_model.fit(\n",
    "    fusion_feature_vector_train, y_train,\n",
    "    epochs=50, batch_size=32,\n",
    "    validation_data=(fusion_feature_vector_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UQn6GX7dsEPY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.4100 - accuracy: 0.8029\n",
      "Test Loss: 0.4100\n",
      "Test Accuracy: 0.8029\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model\n",
    "loss, accuracy = classification_model.evaluate(fusion_feature_vector_train, y_train)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_V0sdSojsCkp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8034\n",
      "Test Loss: 0.4425\n",
      "Test Accuracy: 0.8034\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model\n",
    "loss, accuracy = classification_model.evaluate(fusion_feature_vector_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzEL9--eSEmB"
   },
   "source": [
    "### Keras Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bjGkwJTfSGzx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Obtaining dependency information for keras-tuner from https://files.pythonhosted.org/packages/2b/39/21f819fcda657c37519cf817ca1cd03a8a025262aad360876d2a971d38b3/keras_tuner-1.4.6-py3-none-any.whl.metadata\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.9 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 30.7/128.9 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ----------------- 71.7/128.9 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 112.6/128.9 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- 128.9/128.9 kB 847.7 kB/s eta 0:00:00\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IwnW_v5dvYh7"
   },
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras.models import Model\n",
    "from keras import callbacks\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "\n",
    "# Assuming you have fusion_feature_vector_train, y_train, fusion_feature_vector_val, y_val\n",
    "\n",
    "def build_model(hp):\n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=(fusion_feature_vector_train.shape[1],))\n",
    "\n",
    "    # Initial hyperparameters\n",
    "    units = hp.Int('units', min_value=32, max_value=256, step=20)\n",
    "    dropout_rate = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.01)\n",
    "    num_hidden_layers = hp.Int('num_hidden_layers', min_value=1, max_value=10, step=1)\n",
    "\n",
    "    x = input_layer\n",
    "\n",
    "    # Add hidden layers based on the hyperparameter\n",
    "    for _ in range(num_hidden_layers):\n",
    "        x = Dense(units, activation='relu')(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Build the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "FX-VekqyRmuC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from keras_tuner_dir\\classification_tuner\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define the tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='classification_tuner'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(fusion_feature_vector_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(fusion_feature_vector_val, y_val),\n",
    "             callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Z66JZDfZRhNj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "149/149 [==============================] - 5s 24ms/step - loss: 0.8680 - accuracy: 0.7349 - val_loss: 0.5610 - val_accuracy: 0.7748\n",
      "Epoch 2/50\n",
      "149/149 [==============================] - 3s 23ms/step - loss: 0.5500 - accuracy: 0.7878 - val_loss: 0.5623 - val_accuracy: 0.7748\n",
      "Epoch 3/50\n",
      "149/149 [==============================] - 4s 25ms/step - loss: 0.5081 - accuracy: 0.7916 - val_loss: 0.5671 - val_accuracy: 0.7748\n",
      "Epoch 4/50\n",
      "149/149 [==============================] - 3s 23ms/step - loss: 0.4733 - accuracy: 0.7971 - val_loss: 0.5786 - val_accuracy: 0.7748\n",
      "Epoch 5/50\n",
      "149/149 [==============================] - 4s 24ms/step - loss: 0.4471 - accuracy: 0.7973 - val_loss: 0.5727 - val_accuracy: 0.7748\n",
      "Epoch 6/50\n",
      "149/149 [==============================] - 3s 23ms/step - loss: 0.4369 - accuracy: 0.7973 - val_loss: 0.5790 - val_accuracy: 0.7748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f0e325d890>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Build the final model with the best hyperparameters\n",
    "final_model = build_model(best_hps)\n",
    "\n",
    "# Train the final model\n",
    "final_model.fit(fusion_feature_vector_train, y_train,\n",
    "                epochs=50,\n",
    "                validation_data=(fusion_feature_vector_val, y_val),\n",
    "                callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 1s 4ms/step - loss: 0.5035 - accuracy: 0.7979\n",
      "Test Loss: 0.5035\n",
      "Test Accuracy: 0.7979\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model\n",
    "loss, accuracy = final_model.evaluate(fusion_feature_vector_train, y_train)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5107 - accuracy: 0.7966\n",
      "Test Loss: 0.5107\n",
      "Test Accuracy: 0.7966\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the classification model\n",
    "loss, accuracy = final_model.evaluate(fusion_feature_vector_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on other images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Females: 1217\n",
      "Males: 4733\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in labels:\n",
    "    if i == 0:\n",
    "        c = c+1\n",
    "print(\"Females:\", c)\n",
    "print(\"Males:\", len(labels)-c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLVloazL-gwN"
   },
   "source": [
    "### Exporting Models For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.save(\"saved_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1cw69PDUtZ9B",
    "HCIy1F0ObYc3",
    "mGtzdwk4rsue",
    "HBuBtedZZkaj"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
